<html>

<head>
	<title>Ethical Reflections | 1107</title>
	<link rel="stylesheet" href="../styles/main.css">
	<script src="../scripts/main.js"></script>
</head>

<body>
	<h1>Ethical Issues and Reflections</h1>
	<nav></nav>
	<p>Ethical issues relating to the technology, your personal reflections and recommendations [Individual].</p>

	<table>
		<tr>
			<th colspan="3">Team Member Details</th>
		</tr>
		<tr>
			<th>Last Name</th>
			<th>First Name</th>
			<th>Student ID</th>
		</tr>
		<tr>
			<td>Evans</td>
			<td>Nate</td>
			<td>21144881</td>
		</tr>
		<tr>
			<td>Butler</td>
			<td>Blake</td>
			<td>21130958</td>
		</tr>
		<tr>
			<td>Yugendran</td>
			<td>Kishan</td>
			<td>21148803</td>
		</tr>
	</table>

	<!--
	<p>
		<em>
			Note: the preferred option will be to fill in the cells in your site with 'hard coded'
			details in this form in a row, and email the link to your TA when completed.
		</em>
	</p>


	<h5>Link to page or area in the team discussion board or your Personal Repository [you can make this private if you wish]: </h5>
	<a>
		Portfolio Repository Individual [Your Team and Individual Name] Link
	</a>

	<hr />
	<p>
		<em>Note: you can replace the Link to Canvas Comp501 with a'hard coded' link to your personal repository in this form or equivalent.</em>
	</p>
	-->


	<hr>
	<h2>Nate: Ethical Reflections</h2>
	<p>
		In doing this assignment I have learnt about several important ethical issues regarding autonomous vehicles.
		There are a couple of professional ethical principles that self-driving AIs in their current state are at risk of breaching.
		In particular, the main potential breaches are the avoidance of harm and not acting in a discriminatory or biased manner.
	</p>
	<p>
		The risk of harm is due to self-driving AI having to have prepared for situations in which it must choose an option that it decided would inflict the
		least amount of harm.
		I find this quite problematic because this AI's programming would have a case in which it decides purposefully to inflict harm to some entity, even if
		it is a justifiable decision based on the AI determining that that outcome would be the least damaging.
		For instance, it is logically obvious that when given the choice between crashing into a car or into a bicycle that it would be better to crash into the
		car; however the fact that this outcome includes a purposeful collision may be quite unsettling.
		People would not want to drive in or be around a vehicle that may lead to them being crashed into on purpose, or otherwise being at risk of being harmed
		by a purposeful decision made by an AI.
	</p>
	<p>
		The determination of these priorities would also having some unavoidable level of bias built into the methodology.
		I can see some potential issues with this.
		For instance, the best moral decision may not be able to be made properly if not all factors are taken into account by the AI.
		There is also a more sinister level of bias in what amount of training data is given to the AI which can lead to, for instance, darker-skinned people
		having lower detection rates than lighter-skinned people, which is obviously a massive problem.
		Biases need to be addressed in the training data stage before the output is loaded into the autonomous AI.
	</p>
	<p>
		Overall I feel like there are quite a few ethical issues regarding self-driving vehicles that I feel are still yet to be thoroughly addressed, which
		must be done decisively before autonomous vehicles become common on our roads.
		There is also the social aspect that must be looked into, at what the general population thinks of autonomous vehicles and the potential ethical/moral
		decisions to be made by them while driving.
		People may remain uncomfortable with them for some time and get put off self-driving vehicles permanently if these issues with self-driving AI seep into
		public consciousness.
		I think more should be done to alleviate people's potential concerns about autonomous vehicles before they become mainstream.
	</p>

	
	<hr>
	<h2>Blake: Ethical Reflections</h2>
	<p>
		During this assignment I found that self-driving cars raise some tough ethical issues. The main one being the question of what happens when a self-driving car 
		is involved in a traffic accident? Or what happens when a self-driving car causes the death of its passenger or someone else? These questions are difficult to answer 
		as it would be problematic to hold a driver responsible when the AI was in control. For obvious reasons it would be redundant to hold the AI accountable as well, 
		so then would it be the programmer at fault? However, a self-driving AI would be created through the efforts of a team of different programmers so it would be 
		difficult to find someone to take responsibility. 
	</p>
	<p>
		If an accident occurred and was confirmed to be caused by a self-driving car, I think it is highly likely the model of car would be pulled by the manufacturer 
		for an update or be discontinued. This would put a dent in the reputation of the manufacturers as well as self-driving cars in general and potentially reduce 
		the public’s trust in driverless cars. I can see how this could place immense pressure on the programmers and manufacturers to create a perfect car that never 
		makes mistakes.  
	</p>
	<p>
		There is also the scenario where a self-driving car is approaching a crossing with pedestrians when the brakes suddenly fail. Should the cars AI steer away, 
		injuring or killing its passengers? Or continue straight, injuring or killing innocent pedestrians? Personally, it’s difficult to determine what the morally 
		correct answer is as either way it’s a situation that should never happen. I believe at the very least these cars should be equipped with enough safety features 
		to prevent these kinds of events from happening at all. For example, sensors could be implemented to monitor brake functionality as well as emergency backup brakes. 
		However, it is difficult to prepare for everything and there will need to be a predetermined action coded into the AI should a similar event occur.  This means 
		these tough ethical questions must be answered before any finished product can be completed.
	</p>
	<p>
		One potential way of solving this issue is a screening process when purchasing a self-driving car that determine who will be using the car and whether they would 
		prefer if, in a worst-case scenario, they would prefer the car prioritise their own safety or not. However, this is a rudimentary solution to this issue and could 
		also be seen as un-ethical. 
	</p>


	<hr>
	<h2>Kishan: Ethical Reflections</h2>
	<p>
		While doing this assignment I learnt the important ethical issues of having Self-driving cars on the streets.
   		Mainly the idea of what would happen if a collision were to take place causing the passenger to be hurt in any way. Who would be to blame?
		This question is hard one to tackle taking into consideration that a collision could really be an anomaly that would not have. occurred during
		testing.	
	</p>
	<p>
		People wonder how the AI's decision making capabilities would impact the car. For example what would the car do if there were a pedestrian that ran
		across the crossing at the last moment. Would the car brake or would it not be able to detect it clear enough? What if the person is hidden behind an
		object? Would the sensors pick it up as a hazard? These questions tend to cause a lot of unease in the driving community as they put their lives on the
		line with an autonomous vehicle that lacks human emotions. A person would slow regardless of a presence of a person just due to the fact that there is
		a hinderance in the line of sight. Would the AI do the same?
	</p>
	<p>
		Accidents are prone to happen as there will be unforseen circumstances on the road that would differ from it's testings.
		People around the world will need to hold someone responsible if the autonomous vehicle were to collide with another object putting lives in danger.
		The best way to fix this is to firstly, make people regain their trust in the company or specifically the auto-driving feature of the car.
		Secondly, the companies responsible for the car would need to tweak the program and model of the car to create a safer environment for the
		consumers to be in allowing them to be more comfortable in the car.  This would be driven by the safety factor of the car. If an accident were
		to occur companies would have to re-establish the sense of security they had built to regain the trust of the consumers that would impact
		the sales of the car. This as a result, would allow people to regain their trust in the company which is easier said than done.
		However, this may take a long time to act out but I personally feel that this is the best way to work around this scenario.
	</p>
	
		
	<footer></footer>
</body>

</html>
